import pyrealsense2 as rs
import numpy as np
import cv2
from ultralytics import YOLO

# åˆå§‹åŒ– YOLOv8 æ¨¡å‹
model = YOLO("yolov10m.pt")  # å¯æ”¹ yolov8n.pt ç­‰

# RealSense è¨­å®š
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

# å˜—è©¦å•Ÿå‹•æ”å½±æ©Ÿ
try:
    profile = pipeline.start(config)
    device = profile.get_device()
    name = device.get_info(rs.camera_info.name)
    serial = device.get_info(rs.camera_info.serial_number)
    print(f"âœ… å·²å•Ÿç”¨è£ç½®ï¼š{name}ï¼Œåºè™Ÿï¼š{serial}")
except Exception as e:
    print("âŒ RealSense å•Ÿå‹•å¤±æ•—ï¼š", e)
    exit(1)

# å°é½Šè¨­å®š
align = rs.align(rs.stream.color)

# å–å¾—æ·±åº¦æ¯”ä¾‹å°º
depth_sensor = profile.get_device().first_depth_sensor()
depth_scale = depth_sensor.get_depth_scale()
print(f"ğŸ“ æ·±åº¦æ¯”ä¾‹å°ºï¼š{depth_scale} ç±³/å–®ä½")

print("ğŸš€ é–‹å§‹åµæ¸¬ï¼ˆæŒ‰ Q éµçµæŸï¼‰")

try:
    while True:
        frames = pipeline.wait_for_frames()
        aligned_frames = align.process(frames)
        depth_frame = aligned_frames.get_depth_frame()
        color_frame = aligned_frames.get_color_frame()

        if not depth_frame or not color_frame:
            print("âš ï¸ ç„¡æ³•å–å¾—å½±åƒ")
            continue

        depth_image = np.asanyarray(depth_frame.get_data())
        color_image = np.asanyarray(color_frame.get_data())

        # YOLO åµæ¸¬
        results = model(color_image)[0]
        annotated_image = results.plot()

        # è™•ç†æ¯å€‹åµæ¸¬æ¡†
        for box in results.boxes:
            # é‚Šæ¡†èˆ‡æ¨™ç±¤
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cx = int((x1 + x2) / 2)
            cy = int((y1 + y2) / 2)

            # æ·±åº¦å€¼
            depth = depth_frame.get_distance(cx, cy)

            # ç©ºé–“åº§æ¨™
            intrinsics = depth_frame.profile.as_video_stream_profile().intrinsics
            X, Y, Z = rs.rs2_deproject_pixel_to_point(intrinsics, [cx, cy], depth)

            # é¡åˆ¥åç¨±
            class_id = int(box.cls[0])
            class_name = model.names[class_id]

            # é¡¯ç¤ºæ¨™ç±¤
            label = f"{class_name}: ({X:.2f}, {Y:.2f}, {Z:.2f}) m"
            cv2.putText(annotated_image, label, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)

        # é¡¯ç¤ºç•«é¢
        cv2.imshow("YOLOv8 + RealSense 3D", annotated_image)

        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

finally:
    pipeline.stop()
    cv2.destroyAllWindows()
    print("ğŸ›‘ å·²çµæŸåµæ¸¬")
